{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3479aab9",
   "metadata": {},
   "source": [
    "# Lab: Shrinkage Methods\n",
    "\n",
    "This chapter follows closely chapter 6 of James et al. (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f32a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e643fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy<2.0\n",
      "  Downloading numpy-1.26.4-cp39-cp39-win_amd64.whl (15.8 MB)\n",
      "     -------------------------------------- 15.8/15.8 MB 142.5 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\tthivillon\\AppData\\Roaming\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Accès refusé: 'C:\\\\Users\\\\tthivillon\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages\\\\~umpy.libs\\\\libscipy_openblas64_-caad452230ae4ddb57899b8b3a33c55c.dll'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install \"numpy<2.0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a121caba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 390, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tthivillon\\AppData\\Local\\Temp\\ipykernel_5124\\2279076252.py\", line 3, in <module>\n",
      "    from matplotlib.pyplot import subplots\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\", line 109, in <module>\n",
      "    from . import _api, _version, cbook, docstring, rcsetup\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, cbook, scale\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\scale.py\", line 23, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\", line 136, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\", line 46, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5124\\2279076252.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msubplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOLS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;31m# cbook must import matplotlib only within function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;31m# definitions, so it is safe to import from it here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMatplotlibDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msanitize_sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmplDeprecation\u001b[0m  \u001b[1;31m# deprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\rcsetup.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mls_mapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_color_like\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontconfig_pattern\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparse_fontconfig_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enums\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJoinStyle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCapStyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\colors.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_color_data\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBASE_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTABLEAU_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCSS4_COLORS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXKCD_COLORS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\scale.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m from matplotlib.ticker import (\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mNullFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mScalarFormatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogFormatterSciNotation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogitFormatter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mNullLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLogLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoLocator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoMinorLocator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\ticker.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[0m_log\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_api\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m from matplotlib._path import (\n\u001b[0m\u001b[0;32m     47\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     48\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.api import OLS\n",
    "import sklearn.model_selection as skm\n",
    "import sklearn.linear_model as skl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ISLP import load_data\n",
    "from ISLP.models import ModelSpec as MS\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846a10e",
   "metadata": {},
   "source": [
    "We again collect the new imports\n",
    "needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b5adfb",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xf but this version of numpy is 0xe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;31mRuntimeError\u001b[0m: module compiled against API version 0xf but this version of numpy is 0xe"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27928\\1194489368.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_decomposition\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPLSRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mISLP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m      (Stepwise,\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0m_distributor_init\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     )\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\sparse\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_lil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\sparse\\_csr.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_matrix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_array_doc_to_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_spbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m from ._sparsetools import (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001b[0m\u001b[0;32m     12\u001b[0m                            get_csr_submatrix)\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_sputils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mupcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from ISLP.models import \\\n",
    "     (Stepwise,\n",
    "      sklearn_selected,\n",
    "      sklearn_selection_path)\n",
    "#!pip install l0bnb\n",
    "#from l0bnb import fit_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363de72",
   "metadata": {},
   "source": [
    "When we talk about big data, we do not only talk about larger sample size ($n$), but also about a larger number of dependant variables ($p$). However, with OLS, we are limited by the identification constraint that $p<n$. In addition, we would like to have $p$ way smaller than $n$ for inference and prediction accuracy.\n",
    "\n",
    "\n",
    "This lab presents methods to use a least squares fit in a setting in which the number of dependent variables,$p$, is large with respect to the sample size, $n$. \n",
    "\n",
    "\n",
    "## Shrinkage methods\n",
    "\n",
    "Model selection methods constrained the number of varaibles *before* running a linear regression. Shrinkage methods try to run a linear regression while constraining the number of covariates/predictor variables. In particular they penalize high values of the parameters in the objective function resulting in shrunken coefficients.\n",
    "\n",
    "We will use the `sklearn.linear_model` package (for which\n",
    "we use `skl` as shorthand below)\n",
    "to fit ridge and  lasso regularized linear models on the `Hitters` data.\n",
    "We start with the model matrix `X` (without an intercept) that we computed in the previous section on best subset regression.\n",
    " \n",
    "We will  apply shrinkage methods to the  `Hitters` \n",
    "data.  We wish to predict a baseball player’s `Salary` on the\n",
    "basis of various statistics associated with performance in the\n",
    "previous year.\n",
    "\n",
    "First of all, we note that the `Salary` variable is missing for\n",
    "some of the players.  The `np.isnan()`  function can be used to\n",
    "identify the missing observations. It returns an array\n",
    "of the same shape as the input vector, with a `True` for any elements that\n",
    "are missing, and a `False` for non-missing elements.  The\n",
    "`sum()`  method can then be used to count all of the\n",
    "missing elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6e940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Hitters = load_data('Hitters')\n",
    "np.isnan(Hitters['Salary']).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d2256-2803-4bbe-8353-b063b669e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d79c0",
   "metadata": {},
   "source": [
    " We see that `Salary` is missing for 59 players. The\n",
    "`dropna()`  method of data frames removes all of the rows that have missing\n",
    "values in any variable (by default --- see  `Hitters.dropna?`).\n",
    "Note: we are dropping the missing, but it is not always the best option. For instance in case of differential attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3472ea4b",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Hitters = Hitters.dropna();\n",
    "Hitters.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a17487",
   "metadata": {},
   "source": [
    "We will fit the biggest model, using all the variables. Here we excluded the first column corresponding to the intercept, since the methods we will use will fit the intercept separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c796192",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "design = MS(Hitters.columns.drop('Salary')).fit(Hitters)\n",
    "Y = np.array(Hitters['Salary'])\n",
    "D = design.fit_transform(Hitters)\n",
    "D = D.drop('intercept', axis=1)\n",
    "X = np.asarray(D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a9e92-ab9d-47db-ba16-28440e0b0365",
   "metadata": {},
   "source": [
    "## Shrinkage methods\n",
    "\n",
    "\n",
    "\n",
    "### Ridge Regression\n",
    "\n",
    "Recall that the Ridge Regression objective function is: \n",
    "$$ \\hat{\\beta}^{R}= arg min_{\\beta} \\sum_{i=1}^{n}(y_{i} - \\beta_{0} - \\sum_{j=1}^{p} \\beta_{j}x_{ij})^2 + \\lambda \\sum_{j=1}^p \\beta^{2}_{j}  = RSS + \\lambda \\sum_{j=1}^p \\beta^{2}_{j} $$\n",
    "with $\\lambda>0$ is a tuning parameter regulating the penalties applied on large parameter.\n",
    "\n",
    "\n",
    "We will use the function `skl.ElasticNet()` to fit both  ridge and the lasso.\n",
    "To fit a *path* of ridge regressions models, we use\n",
    "`skl.ElasticNet.path()`, which can fit both ridge and lasso, as well as a hybrid mixture;  ridge regression\n",
    "corresponds to `l1_ratio=0`.\n",
    "It is good practice to standardize the columns of `X` in these applications, why? The main reason is that if variables are measured in different units, those with higher values could be perceived as having higher contributions to the model while it is not the case. Since `skl.ElasticNet()` **does not do normalization**, we have to take care of that ourselves.\n",
    "\n",
    "Since we standardize first, in order to find coefficient\n",
    "estimates on the original scale, we must *unstandardize*\n",
    "the coefficient estimates. The parameter $\\lambda$ in $RSS + \\lambda \\sum^{p}_{j=1}\\beta^{2}_{j}$ (Ridge 6.5) and $RSS + \\lambda \\sum^{p}_{j=1}| \\beta_{j}| $ (Lasso 6.7) is called `alphas` in `sklearn`. In order to\n",
    "be consistent with the rest of this chapter, we use `lambdas`\n",
    "rather than `alphas` in what follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fc533",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Standardize in the first 3 rows\n",
    "Xs = X - X.mean(0)[None,:]\n",
    "X_scale = X.std(0)\n",
    "Xs = Xs / X_scale[None,:]\n",
    "#Compute the lambdas\n",
    "lambdas = 10**np.linspace(8, -2, 100) / Y.std()\n",
    "#Apply ridge regression\n",
    "soln_array = skl.ElasticNet.path(Xs,\n",
    "                                 Y,\n",
    "                                 l1_ratio=0.,\n",
    "                                 alphas=lambdas)[1]\n",
    "soln_array.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefe307b",
   "metadata": {},
   "source": [
    "Here we extract the array of coefficients corresponding to the solutions along the regularization path.\n",
    "\n",
    "By default the `skl.ElasticNet.path` method fits a path along\n",
    "an automatically selected range of $\\lambda$ values, except for the case when\n",
    "`l1_ratio=0`, which results in ridge regression (as is the case here). {The reason is rather technical; for all models except ridge, we can find the smallest value of $\\lambda$ for which all coefficients are zero. For ridge this value is $\\infty$.}  \n",
    "\n",
    "So here we have chosen to implement the function over a grid of values ranging\n",
    "from $\\lambda=10^{8}$ to $\\lambda=10^{-2}$ scaled by the standard\n",
    "deviation of $y$, essentially covering the full range of scenarios\n",
    "from the null model containing only the intercept, to the least\n",
    "squares fit.\n",
    "\n",
    "Associated with each value of $\\lambda$ is a vector of ridge\n",
    "regression coefficients,   that can be accessed by\n",
    "a column of `soln_array`. In this case, `soln_array` is a $19 \\times 100$ matrix, with\n",
    "19 rows (one for each predictor) and 100\n",
    "columns (one for each value of $\\lambda$).\n",
    "\n",
    "We transpose this matrix and turn it into a data frame to facilitate viewing and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642287d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n",
    "soln_path.index.name = 'negative log(lambda)'\n",
    "soln_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2a5cd7",
   "metadata": {},
   "source": [
    "We plot the paths to get a sense of how the coefficients vary with $\\lambda$.\n",
    "To control the location of the legend we first set `legend` to `False` in the\n",
    "plot method, adding it afterward with the `legend()` method of `ax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734c1a05",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficients', fontsize=10)\n",
    "ax.legend(loc='upper left');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cfe676",
   "metadata": {},
   "source": [
    "(We have used `latex` formatting in the horizontal label, in order to format the Greek $\\lambda$ appropriately.) \n",
    "We expect the coefficient estimates to be much smaller, in terms of\n",
    "$\\ell_2$ norm, when a large value of $\\lambda$ is used, as compared to\n",
    "when a small value of $\\lambda$ is used. (Recall that the  $\\ell_2$ norm is the square root of the sum of squared coefficient values.) We display  the coefficients at the $40$th step,\n",
    "where $\\lambda$ is 25.535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a55b76b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[39]]\n",
    "lambdas[39], beta_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4071c",
   "metadata": {},
   "source": [
    "Let’s compute the $\\ell_2$ norm of the standardized coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbee899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(beta_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2511270d",
   "metadata": {},
   "source": [
    "In contrast, here is the $\\ell_2$ norm when $\\lambda$ is 2.44e-01.\n",
    "Note the much larger $\\ell_2$ norm of the\n",
    "coefficients associated with this smaller value of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe1cb5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "beta_hat = soln_path.loc[soln_path.index[59]]\n",
    "lambdas[59], np.linalg.norm(beta_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c610fcf7",
   "metadata": {},
   "source": [
    "Above we normalized `X` upfront, and fit the ridge model using `Xs`.\n",
    "The `Pipeline()`  object\n",
    "in `sklearn` provides a clear way to separate feature\n",
    "normalization from the fitting of the ridge model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46c4d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge = skl.ElasticNet(alpha=lambdas[59], l1_ratio=0)\n",
    "scaler = StandardScaler(with_mean=True,  with_std=True)\n",
    "pipe = Pipeline(steps=[('scaler', scaler), ('ridge', ridge)])\n",
    "pipe.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5607efa",
   "metadata": {},
   "source": [
    "We show that it gives the same $\\ell_2$ norm as in our previous fit on the standardized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e775d4c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(ridge.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06771f4e",
   "metadata": {
    "tags": []
   },
   "source": [
    " Notice that the operation `pipe.fit(X, Y)` above has changed the `ridge` object, and in particular has added attributes such as `coef_` that were not there before. \n",
    "### Estimating Test Error of Ridge Regression\n",
    "Choosing an *a priori* value of $\\lambda$ for ridge regression is\n",
    "difficult if not impossible. We will want to use the validation method\n",
    "or cross-validation to select the tuning parameter.\n",
    "\n",
    "We fix the random state of the splitter\n",
    "so that the results obtained will be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da4f3f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = skm.ShuffleSplit(n_splits=1,\n",
    "                              test_size=0.5,\n",
    "                              random_state=17092023)\n",
    "ridge.alpha = 0.01\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951f3189",
   "metadata": {},
   "source": [
    "The test MSE is 1.47e+05.  Note\n",
    "that if we had instead simply fit a model with just an intercept, we\n",
    "would have predicted each test observation using the mean of the\n",
    "training observations. We can get the same result by fitting a ridge regression model\n",
    "with a *very* large value of $\\lambda$. Note that `1e10`\n",
    "means $10^{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6abcd6",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge.alpha = 1e10\n",
    "results = skm.cross_validate(ridge,\n",
    "                             X,\n",
    "                             Y,\n",
    "                             scoring='neg_mean_squared_error',\n",
    "                             cv=validation)\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60702c2d",
   "metadata": {},
   "source": [
    "Obviously choosing $\\lambda=0.01$ is arbitrary,  so we will  use cross-validation or the validation-set\n",
    "approach to choose the tuning parameter $\\lambda$.\n",
    "The object `GridSearchCV()`  allows exhaustive\n",
    "grid search to choose such a parameter.\n",
    "\n",
    "We first use the validation set method\n",
    "to choose $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4009c7c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {'ridge__alpha': lambdas}\n",
    "grid = skm.GridSearchCV(pipe,\n",
    "                        param_grid,\n",
    "                        cv=validation,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22f625",
   "metadata": {},
   "source": [
    "Alternatively, we can use 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd51cd6",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "kfold = skm.KFold(K,\n",
    "                  random_state=0,\n",
    "                  shuffle=True)\n",
    "\n",
    "grid = skm.GridSearchCV(pipe, \n",
    "                        param_grid,\n",
    "                        cv=kfold,\n",
    "                        scoring='neg_mean_squared_error')\n",
    "grid.fit(X, Y)\n",
    "grid.best_params_['ridge__alpha']\n",
    "grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245526c5",
   "metadata": {},
   "source": [
    "We now plot the cross-validated MSE as a function of $-\\log(\\lambda)$, which has shrinkage decreasing from left\n",
    "to right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679fd6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            -grid.cv_results_['mean_test_score'],\n",
    "            yerr=grid.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cc5ca2",
   "metadata": {},
   "source": [
    "One can cross-validate different metrics to choose a parameter. The default\n",
    "metric for `skl.ElasticNet()` is test $R^2$.\n",
    "Let’s compare $R^2$ to MSE for cross-validation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59557ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_r2 = skm.GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=kfold)\n",
    "grid_r2.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac19760",
   "metadata": {},
   "source": [
    "Finally, let’s plot the results for cross-validated $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d94ae6",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "r2_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            grid_r2.cv_results_['mean_test_score'],\n",
    "            yerr=grid_r2.cv_results_['std_test_score'] / np.sqrt(K))\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated $R^2$', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eda9aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fast Cross-Validation for Solution Paths\n",
    "The ridge, lasso, and elastic net can be efficiently fit along a sequence of $\\lambda$ values, creating what is known as a *solution path* or *regularization path*. Hence there is specialized code to fit\n",
    "such paths, and to choose a suitable value of $\\lambda$ using cross-validation. \n",
    "\n",
    "Even with identical splits the results will not agree *exactly* with our `grid`\n",
    "above because the standardization of each feature  in `grid` is carried out on each fold,\n",
    "while in `pipeCV` below it is carried out only once.\n",
    "Nevertheless, the results are similar as the normalization\n",
    "is relatively stable across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd1281",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas, \n",
    "                           l1_ratio=0,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)])\n",
    "pipeCV.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8395bb",
   "metadata": {},
   "source": [
    "Let’s produce a plot again of the cross-validation error to see that\n",
    "it is similar to using `skm.GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf09512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_ridge = pipeCV.named_steps['ridge']\n",
    "ridgeCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(lambdas),\n",
    "            tuned_ridge.mse_path_.mean(1),\n",
    "            yerr=tuned_ridge.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_ridge.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5eb495",
   "metadata": {},
   "source": [
    "We see that the value of $\\lambda$ that results in the\n",
    "smallest cross-validation error is 1.115e-02, available\n",
    "as the value `tuned_ridge.alpha_`. What is the test MSE\n",
    "associated with this value of $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6770f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.min(tuned_ridge.mse_path_.mean(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da37400",
   "metadata": {},
   "source": [
    "Note: In this line of code the function `np.min()` returns the lowest value of the MSE for all values of $\\lambda$ in our search grid.\n",
    "\n",
    "This represents a further improvement over the test MSE that we got\n",
    "using $\\lambda=0.01$.  Finally, `tuned_ridge.coef_`\n",
    "has the coefficients fit on the entire data set\n",
    "at this value of  $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b1e39",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_ridge.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ea5623",
   "metadata": {},
   "source": [
    "As expected, none of the coefficients are zero—ridge regression does\n",
    "not perform variable selection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01383a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating Test Error of Cross-Validated Ridge\n",
    "Choosing $\\lambda$ using cross-validation provides a single regression\n",
    "estimator, similar to fitting a linear regression model. It is therefore reasonable to estimate what its test error is. \n",
    "\n",
    "We run into a problem here in that cross-validation will have\n",
    "*touched* all of its data in choosing $\\lambda$, hence we have no\n",
    "further data to estimate test error.\n",
    "\n",
    "A compromise is to do an initial\n",
    "split of the data into two disjoint sets: a training set and a test set.\n",
    "We then fit a cross-validation\n",
    "tuned ridge regression on the training set, and evaluate its performance on the test set.\n",
    "\n",
    "We might call this cross-validation nested\n",
    "within the validation set approach. A priori there is no reason to use\n",
    "half of the data for each of the two sets in validation. Below, we use\n",
    "75% for training and 25% for test, with the estimator being ridge\n",
    "regression tuned using 5-fold cross-validation.  This can be achieved\n",
    "in code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6259f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outer_valid = skm.ShuffleSplit(n_splits=1, \n",
    "                               test_size=0.25,\n",
    "                               random_state=1)\n",
    "inner_cv = skm.KFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=2)\n",
    "ridgeCV = skl.ElasticNetCV(alphas=lambdas,\n",
    "                           l1_ratio=0,\n",
    "                           cv=inner_cv)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('ridge', ridgeCV)]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44495e5",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = skm.cross_validate(pipeCV, \n",
    "                             X,\n",
    "                             Y,\n",
    "                             cv=outer_valid,\n",
    "                             scoring='neg_mean_squared_error')\n",
    "-results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fed598e",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecaca1a",
   "metadata": {},
   "source": [
    "### The Lasso\n",
    "\n",
    "Lasso coefficients minimize the following objective function: \n",
    "\n",
    "   $$ \\beta_{L}= arg min_{\\beta} \\sum_{i=1}^{n}(y_{i} - \\beta_{0} - \\sum_{j=1}^{p} \\beta_{j}x_{ij})^2 + \\lambda \\sum_{j=1}^p |\\beta_{j}| $$\n",
    "\n",
    "A consequence of this objective function is that Lasso is much more likely to shrink coefficients to exactly zero, performing variable selection. \n",
    "\n",
    "\n",
    "\n",
    "We saw that ridge regression with a wise choice of $\\lambda$ can\n",
    "outperform least squares as well as the null model on the\n",
    " `Hitters`  data set. We now ask whether the lasso can yield\n",
    "either a more accurate or a more interpretable model than ridge\n",
    "regression. In order to fit a lasso model, we once again use the\n",
    "`ElasticNetCV()`  function; however, this time we use the argument\n",
    "`l1_ratio=1`. Other than that change, we proceed just as we did in\n",
    "fitting a ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae18029",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lassoCV = skl.ElasticNetCV(n_alphas=100, \n",
    "                           l1_ratio=1,\n",
    "                           cv=kfold)\n",
    "pipeCV = Pipeline(steps=[('scaler', scaler),\n",
    "                         ('lasso', lassoCV)])\n",
    "pipeCV.fit(X, Y)\n",
    "tuned_lasso = pipeCV.named_steps['lasso']\n",
    "tuned_lasso.alpha_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9dd06",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "lambdas, soln_array = skl.Lasso.path(Xs, \n",
    "                                    Y,\n",
    "                                    l1_ratio=1,\n",
    "                                    n_alphas=100)[:2]\n",
    "soln_path = pd.DataFrame(soln_array.T,\n",
    "                         columns=D.columns,\n",
    "                         index=-np.log(lambdas))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52817006",
   "metadata": {},
   "source": [
    "We can see from the coefficient plot of the standardized coefficients that depending on the choice of\n",
    "tuning parameter, some of the coefficients will be exactly equal to\n",
    "zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd93a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "soln_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f9a74",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_fig, ax = subplots(figsize=(8,8))\n",
    "soln_path.plot(ax=ax, legend=False)\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Standardized coefficiients', fontsize=20);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e6626",
   "metadata": {},
   "source": [
    "The smallest cross-validated error is lower than the test set MSE of the null model\n",
    "and of least squares, and very similar to the test MSE of 115526.71 of ridge\n",
    "regression  with $\\lambda$ chosen by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b57296a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.min(tuned_lasso.mse_path_.mean(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f35282c",
   "metadata": {},
   "source": [
    "Let’s again produce a plot of the cross-validation error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1a84a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lassoCV_fig, ax = subplots(figsize=(8,8))\n",
    "ax.errorbar(-np.log(tuned_lasso.alphas_),\n",
    "            tuned_lasso.mse_path_.mean(1),\n",
    "            yerr=tuned_lasso.mse_path_.std(1) / np.sqrt(K))\n",
    "ax.axvline(-np.log(tuned_lasso.alpha_), c='k', ls='--')\n",
    "ax.set_ylim([50000,250000])\n",
    "ax.set_xlabel('$-\\log(\\lambda)$', fontsize=20)\n",
    "ax.set_ylabel('Cross-validated MSE', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250e5c0",
   "metadata": {},
   "source": [
    "However, the lasso has a substantial advantage over ridge regression\n",
    "in that the resulting coefficient estimates are **sparse**. Here we see\n",
    "that 6 of the 19 coefficient estimates are exactly zero. So the lasso\n",
    "model with $\\lambda$ chosen by cross-validation contains only 13\n",
    "variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44246aee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuned_lasso.coef_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08d038",
   "metadata": {},
   "source": [
    "As in ridge regression, we could evaluate the test error\n",
    "of cross-validated lasso by first splitting into\n",
    "test and training sets and internally running\n",
    "cross-validation on the training set. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,Rmd",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
