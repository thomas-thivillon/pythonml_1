{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb22af17",
   "metadata": {},
   "source": [
    "# Lab: Cross-Validation and the Bootstrap\n",
    " Some of the commands in this lab may take a while to run on\n",
    "your computer.\n",
    "\n",
    "This chapter follows closely chapter 5 of James et al. (2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd9ebd-298c-411e-bceb-cb88964fd352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ISLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fad148",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS,\n",
    "                         summarize,\n",
    "                         poly)\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5cca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import matplotlib for graphs\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "# Set global parameters\n",
    "%matplotlib inline\n",
    "#plt.style.use('seaborn-white')\n",
    "plt.rcParams['lines.linewidth'] = 3\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fcfe7a",
   "metadata": {},
   "source": [
    "There are several new imports needed for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478aeb4",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import \\\n",
    "     (cross_validate,\n",
    "      KFold,\n",
    "      ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70259b2",
   "metadata": {},
   "source": [
    "As a reminder: resampling methods imply drawing samples successively from a training set and refitting a given model on each sample to obtain new information about the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d30db",
   "metadata": {},
   "source": [
    "## The Validation Set Approach\n",
    "We explore the use of the validation set approach in order to estimate\n",
    "the test error rates that result from fitting various linear models on\n",
    "the  `Auto`  data set.\n",
    "\n",
    "The validation set approach is an easy way to measure the test error associated with fitting a specific statistical learning method. What you have to do is to randomly split the entire dataset you have into two parts:\n",
    "1. **Training set**.\n",
    "2. **Validation set** or hold-out, leave-out, testing set.\n",
    "\n",
    "We first fit the model on the training set to predict $\\hat{y}$ for the observation in the testing set. Then, we assess the test error rate using MSE.\n",
    "\n",
    "\n",
    "We use the function `train_test_split()` to split\n",
    "the data into training and validation sets. As there are 392 observations,\n",
    "we split into two equal sets of size 196 using the\n",
    "argument `test_size=196`. \n",
    "\n",
    "Do not forget to select a random seed, so our results can be reproduced\n",
    "precisely later on. We set the random seed of the splitter\n",
    "with the argument `random_state=28082023`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c95faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                         test_size=196,\n",
    "                                         random_state=28082023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57be35df",
   "metadata": {},
   "source": [
    "Now we can fit a linear regression using only the observations corresponding to the training set `Auto_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b0717d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train['mpg']\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1bef95",
   "metadata": {},
   "source": [
    "We now use the `predict()` method to predict `mpg` for the validation set based on the model matrix\n",
    "obtained using the training set. We also calculate the validation MSE of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea3c0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid['mpg']\n",
    "valid_pred = results.predict(X_valid)\n",
    "np.mean((y_valid - valid_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba5d55",
   "metadata": {},
   "source": [
    "Hence our estimate for the validation MSE of  the linear regression\n",
    "fit is $26.8977$.\n",
    "\n",
    "We can also estimate the validation error for\n",
    "higher-degree polynomial regressions. We first provide a function `evalMSE()` that takes a model string as well\n",
    "as a training and test set and returns the MSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a2d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evalMSE(terms,\n",
    "            response,\n",
    "            train,\n",
    "            test):\n",
    "\n",
    "   mm = MS(terms)\n",
    "   X_train = mm.fit_transform(train)\n",
    "   y_train = train[response]\n",
    "\n",
    "   X_test = mm.transform(test)\n",
    "   y_test = test[response]\n",
    "\n",
    "   results = sm.OLS(y_train, X_train).fit()\n",
    "   test_pred = results.predict(X_test)\n",
    "\n",
    "   return np.mean((y_test - test_pred)**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ab59b1",
   "metadata": {},
   "source": [
    "We use it to estimate the validation MSE\n",
    "using linear, quadratic and cubic fits. We use the `enumerate()`  function\n",
    "here, which gives both the values and indices of objects as one iterates\n",
    "over a for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d93dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e168a",
   "metadata": {},
   "source": [
    "These error rates are $26.897, 20.574$, and $20.801$. \n",
    "\n",
    "***Note***: in case we choose either a different split or random seed, we \n",
    "can expect somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83432f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Auto_train, Auto_valid = train_test_split(Auto,\n",
    "                                          test_size=196,\n",
    "                                          random_state=3)\n",
    "MSE = np.zeros(3)\n",
    "for idx, degree in enumerate(range(1, 4)):\n",
    "    MSE[idx] = evalMSE([poly('horsepower', degree)],\n",
    "                       'mpg',\n",
    "                       Auto_train,\n",
    "                       Auto_valid)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ceb357",
   "metadata": {},
   "source": [
    "Using this split of the observations into a training set and a validation set,\n",
    "we find that the validation set error rates for the models with linear, quadratic, and cubic terms are $20.76$, $16.95$, and $16.97$, respectively.\n",
    "\n",
    "These results are consistent with our previous findings: a model that\n",
    "predicts `mpg` using a quadratic function of `horsepower`\n",
    "performs better than a model that involves only a linear function of\n",
    "`horsepower`, and there is no evidence of an improvement in using a cubic function of `horsepower`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d624a5c",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "### Leave-one-out cross-validation\n",
    "\n",
    "LOOCV involves splitting the dataset into two parts. Unlike the validation set approach, a single observation $i$ is used for the validation set, and the remaining $n-1$ observations are the training set. We fit the model on the $n-1$ training observations and the MSE is calculated using the excluded $i$. We repeat this task $n$ times, for $i=1,\\dot,n$ such as each osbervation is excluded one time. \n",
    "\n",
    "The test MSE is the mean of these $n$ test errors: \n",
    "$ \\mathrm{CV}{(n)}=\\frac{1}{n} \\sum_{i=1}^{n}{MSE}_{i} $\n",
    "\n",
    "- Advantage: less bias because fit the model that contain almost as many observation as in the data set.\n",
    "- Drawback: computationally costly, bias-variance trade-off.\n",
    "\n",
    "\n",
    "In practice, the simplest way to cross-validate in\n",
    "Python is to use `sklearn`, which has a different interface or API\n",
    "than `statsmodels`, the code we have been using to fit GLMs.\n",
    "\n",
    "This is a problem which often confronts data scientists: \"I have a function to do task $A$, and need to feed it into something that performs task $B$, so that I can compute $B(A(D))$, where $D$ is my data.\" When $A$ and $B$ don’t naturally speak to each other, this\n",
    "requires the use of a *wrapper*.\n",
    "The `ISLP` package provides a wrapper, `sklearn_sm()`, that enables us to easily use the cross-validation tools of `sklearn` with\n",
    "models fit by `statsmodels`.\n",
    "\n",
    "The class `sklearn_sm()` \n",
    "has  as its first argument\n",
    "a model from `statsmodels`. It can take two additional\n",
    "optional arguments: `model_str` which can be\n",
    "used to specify a formula, and `model_args` which should\n",
    "be a dictionary of additional arguments used when fitting\n",
    "the model. For example, to fit a logistic regression model\n",
    "we have to specify a `family` argument. This\n",
    "is passed as `model_args={'family':sm.families.Binomial()}`.\n",
    "\n",
    "Here is our wrapper in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc433f",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "hp_model = sklearn_sm(sm.OLS,\n",
    "                      MS(['horsepower']))\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto['mpg']\n",
    "cv_results = cross_validate(hp_model,\n",
    "                            X,\n",
    "                            Y,\n",
    "                            cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_results['test_score'])\n",
    "cv_err\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f6f30",
   "metadata": {},
   "source": [
    "The arguments to `cross_validate()` are as follows: an\n",
    "object with the appropriate `fit()`, `predict()`,\n",
    "and `score()` methods,  an\n",
    "array of features `X` and a response `Y`. \n",
    "We also included an additional argument `cv` to `cross_validate()`: specifying an integer\n",
    "$K$ results in $K$-fold cross-validation. We have provided a value \n",
    "corresponding to the total number of observations, which results in\n",
    "leave-one-out cross-validation (LOOCV). \n",
    "\n",
    "The `cross_validate()`  function produces a dictionary with several components;\n",
    "we simply want the cross-validated test score here (MSE), which is estimated to be 24.23."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527f67f",
   "metadata": {},
   "source": [
    "We can repeat this procedure for increasingly complex polynomial fits.\n",
    "To automate the process, we again\n",
    "use a for loop which iteratively fits polynomial\n",
    "regressions of degree 1 to 5, computes the\n",
    "associated cross-validation error, and stores it in the $i$th element\n",
    "of the vector `cv_error`. The variable `d` in the for loop\n",
    "corresponds to the degree of the polynomial. We begin by initializing the\n",
    "vector. This command may take a couple of seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951ffc8",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f1304",
   "metadata": {},
   "source": [
    "We see a sharp drop in the estimated test MSE between the linear and\n",
    "quadratic fits, but then no clear improvement from using higher-degree polynomials.\n",
    "\n",
    "Above we introduced the `outer()`  method of the `np.power()`\n",
    "function.  The `outer()` method is applied to an operation\n",
    "that has two arguments, such as `add()`, `min()`, or\n",
    "`power()`.\n",
    "It has two arrays as\n",
    "arguments, and then forms a larger\n",
    "array where the operation is applied to each pair of elements of the\n",
    "two arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3610b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "A = np.array([3, 5, 9])\n",
    "B = np.array([2, 4])\n",
    "np.add.outer(A, B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983625b2",
   "metadata": {},
   "source": [
    "In the CV example above, we used $K=n$, but of course we can also use $K<n$. Why we might want to use such an approach? Well, in the present example LOOCV is *somehow* fast as we only have 196 observations here, but we are used to working with much larger data sets. With large datasets LOOCV will be computationally **very** intensive.\n",
    "\n",
    "### k-Fold Cross-validation\n",
    "\n",
    "An alternative is to use k-fold cross-validation. \n",
    "1. Divide randomly the dataset into $k$ groups of $\\approx$ same size\n",
    "2. The 1st fold is used as a validation set, the method is fit on the remaining $k-1$ fold\n",
    "3. The MSE is computed on the observations in the testing fold\n",
    "4. Repeated $k$ times, each time with a different set of observation as a training set.\n",
    "Then, calculate the k-fold CV: \n",
    "\n",
    "$$ \\mathrm{CV}{(k)}=\\frac{1}{k} \\sum_{i=1}^{k} \\mathrm{MSE}_{i} $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The code is very similar to the above (and is significantly faster). Here we use `KFold()` to partition the data into $K=10$ random groups. We use `random_state` to set a random seed and initialize a vector `cv_error` in which we will store the CV errors corresponding to the\n",
    "polynomial fits of degrees one to five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627460d",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10,\n",
    "           shuffle=True,\n",
    "           random_state=0) # use same splits for each degree\n",
    "for i, d in enumerate(range(1,6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M,\n",
    "                          X,\n",
    "                          Y,\n",
    "                          cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "cv_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf6662",
   "metadata": {},
   "source": [
    "Notice that the computation time is much shorter than that of LOOCV.\n",
    " We still see little evidence that using cubic\n",
    "or higher-degree polynomial terms leads to a lower test error than simply\n",
    "using a quadratic fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89127b",
   "metadata": {},
   "source": [
    "The `cross_validate()` function is flexible and can take\n",
    "different splitting mechanisms as an argument. For instance, one can use the `ShuffleSplit()` funtion to implement\n",
    "the validation set approach just as easily as K-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a636468",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = ShuffleSplit(n_splits=1,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation);\n",
    "results['test_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0fb0d5",
   "metadata": {},
   "source": [
    "One can estimate the variability in the test error by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746aeccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation = ShuffleSplit(n_splits=10,\n",
    "                          test_size=196,\n",
    "                          random_state=0)\n",
    "results = cross_validate(hp_model,\n",
    "                         Auto.drop(['mpg'], axis=1),\n",
    "                         Auto['mpg'],\n",
    "                         cv=validation)\n",
    "results['test_score'].mean(), results['test_score'].std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382372da-d0a0-41f5-99ad-cb084e758c6b",
   "metadata": {},
   "source": [
    "Note that this standard deviation is not a valid estimate of the\n",
    "sampling variability of the mean test score or the individual scores, since the randomly-selected training\n",
    "samples overlap and hence introduce correlations. But it does give an\n",
    "idea of the Monte Carlo variation\n",
    "incurred by picking different random folds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310fe80",
   "metadata": {},
   "source": [
    "\n",
    "## The Bootstrap\n",
    "\n",
    "The bootstrap is a statistical tool that can be used to assess the uncertainty associated with a given estimator or statistical learning method.  Not super useful if you are doing linear regression because we have formula for the standard errors. However, there are many models (almost all actually) for which there exists no closed solution to the estimator variance.\n",
    "\n",
    "With the bootstrap, we have distinct datasets by repeatedly sampling observations from the original dataset. It can be easily applied to a wide range of models.\n",
    "\n",
    "\n",
    "### Estimating the Accuracy of a Statistic of Interest\n",
    "One of the great advantages of the bootstrap approach is that it can\n",
    "be applied in almost all situations. No complicated mathematical\n",
    "calculations are required. While there are several implementations\n",
    "of the bootstrap in Python, its use for estimating\n",
    "standard error is simple enough that we write our own function\n",
    "below for the case when our data is stored\n",
    "in a dataframe.\n",
    "\n",
    "To illustrate the bootstrap, we\n",
    "start with a simple example proposed in section 5.2 of James et al. (2023).\n",
    "We rely on the  `Portfolio`  data set. We wish to invest a fixed sum of money in two assets `X` and `Y` while minimizing the risk associated with these investments. The risk is given by: \n",
    "\n",
    "$$ Var(\\alpha X + (1 - \\alpha)Y) $$\n",
    "\n",
    "where $\\alpha$ is the share of our money that we plan to invest in `X` and $1-\\alpha$ the share invested in `Y`. The objective is to estimate the\n",
    "sampling variance of the parameter $\\hat{\\alpha}$ given in formula (5.7) (note: $\\hat{\\alpha}$ is the value of $\\alpha$ which sets the derivative of $Var(\\alpha X + (1 - \\alpha)Y) $ equal to 0):\n",
    "\n",
    "$$ \\hat{\\alpha}=\\frac{\\hat{\\sigma}^2_Y - \\hat{\\sigma}_{XY}}{\\hat{\\sigma}^2_X + \\hat{\\sigma}^2_Y - 2\\hat{\\sigma}_{XY}} $$\n",
    "\n",
    "We will\n",
    "create a function\n",
    "`alpha_func()`, which takes as input a dataframe `D` assumed\n",
    "to have columns `X` and `Y`, as well as a\n",
    "vector `idx` indicating which observations should be used to\n",
    "estimate \n",
    "$\\hat\\alpha$. The function then outputs the estimate for $\\alpha$ based on\n",
    "the selected observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa53d0c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "Portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "   cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)\n",
    "   return ((cov_[1,1] - cov_[0,1]) /\n",
    "           (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e98801",
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd439170",
   "metadata": {},
   "source": [
    "This function returns an estimate for $\\alpha$\n",
    "based on applying the minimum\n",
    "    variance formula (5.7) to the observations indexed by\n",
    "the argument `idx`.  For instance, the following command\n",
    "estimates $\\alpha$ using all 100 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c9564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha_func(Portfolio, range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc18244c",
   "metadata": {},
   "source": [
    "Next we randomly select\n",
    "100 observations from `range(100)`, with replacement. This is equivalent\n",
    "to constructing a new bootstrap data set and recomputing $\\hat{\\alpha}$\n",
    "based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5754d6d5",
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(Portfolio,\n",
    "           rng.choice(100,\n",
    "                      100,\n",
    "                      replace=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97e132",
   "metadata": {},
   "source": [
    "This process can be generalized to create a simple function `boot_SE()` for\n",
    "computing the bootstrap standard error for arbitrary\n",
    "functions that take only a data frame as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8320a49c",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def boot_SE(func,\n",
    "            D,\n",
    "            n=None,\n",
    "            B=1000,\n",
    "            seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index,\n",
    "                         n,\n",
    "                         replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d25cfe",
   "metadata": {},
   "source": [
    "Notice the use of `_` as a loop variable in `for _ in range(B)`. This is often used if the value of the counter is\n",
    "unimportant and simply makes sure  the loop is executed `B` times.\n",
    "\n",
    "Let’s use our function to evaluate the accuracy of our\n",
    "estimate of $\\alpha$ using $B=1{,}000$ bootstrap replications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e656aa1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha_SE = boot_SE(alpha_func,\n",
    "                   Portfolio,\n",
    "                   B=1000,\n",
    "                   seed=0)\n",
    "alpha_SE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf0c722-6c06-4f59-865c-5c7590ff0325",
   "metadata": {},
   "source": [
    "The final output shows that the bootstrap estimate for ${\\rm SE}(\\hat{\\alpha})$ is $0.0912$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11a71f",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,Rmd",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
